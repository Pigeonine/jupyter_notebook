{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2f7f5e-0a93-4353-8ec7-ace6f1ae3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('.env', 'w') as f:\n",
    "    f.write('OPENAI_API_KEY=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')\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"test\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e542c2-e5ff-43dc-af15-43a4c869a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "# 설치: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ca63be-253f-4971-8665-52fcc03ee70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[API KEY]\n",
      "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\n",
      "[LANGCHAIN_TRACING_V2]\n",
      "true\n",
      "[LANGCHAIN_ENDPOINT]\n",
      "https://api.smith.langchain.com\n",
      "[LANGCHAIN_API_KEY]\n",
      "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\n",
      "[LANGCHAIN_PROJECT]\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")\n",
    "print(f\"[LANGCHAIN_TRACING_V2]\\n{os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "print(f\"[LANGCHAIN_ENDPOINT]\\n{os.environ['LANGCHAIN_ENDPOINT']}\")\n",
    "print(f\"[LANGCHAIN_API_KEY]\\n{os.environ['LANGCHAIN_API_KEY']}\")\n",
    "print(f\"[LANGCHAIN_PROJECT]\\n{os.environ['LANGCHAIN_PROJECT']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c85317c-bdfb-498f-a838-0c621610b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "RAG\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"RAG\")\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "#logging.langsmith(\"Test\", set_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efbc0f05-2fa4-4631-ad6e-d04a8840b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings,FastEmbedEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc74e118-ebc0-4bce-a4b3-4d9fa19e4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\") #단일 pdf\n",
    "loader = PyPDFDirectoryLoader(\"./data\") #여러개 pdf\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "#text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator=\" \")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = OpenAIEmbeddings() #OpenAi 기반\n",
    "#embeddings = HuggingFaceBgeEmbeddings() #HuggingFace 기반(free)\n",
    "#embeddings =FastEmbedEmbeddings() #open source\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장.\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings) #FAISS사용\n",
    "#vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings) #chroma 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa03c502-f05d-4ad4-b808-21e4fb2036e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"You are an assistant for question-answering tasks. \n",
    "# Use the following pieces of retrieved context to answer the question. \n",
    "# If you don't know the answer, just say that you don't know. \n",
    "# Answer in Korean.\n",
    "\n",
    "# #Question: \n",
    "# {question} \n",
    "# #Context: \n",
    "# {context} \n",
    "\n",
    "# #Answer:\"\"\"\n",
    "# )\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") #hub에서 가져온 rag 프롬프트\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.2)\n",
    "#llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08cb79b6-e97a-4db2-8c3b-b3b5dbe5402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeYO 논문에서는 DeYO의 성능을 다양한 시나리오에서 기존 방법들과 비교하고, 새로운 신뢰도 지표인 PLPD의 역할을 분석하며, 각 구성 요소가 성능에 미치는 영향을 평가하는 실험을 설계했습니다. 이 연구는 실제 상황을 반영한 편향된 시나리오와 야생 시나리오에서의 성능을 중점적으로 다룹니다. 또한, 하이퍼파라미터가 DeYO의 성능에 미치는 정도도 조사합니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"DeYO 논문 내용을 요약해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24b1de94-07f4-4d19-9e2b-3a905a05e201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoTTA는 사전 훈련된 모델에 통합할 수 있는 새로운 방법을 제안하며, 소스 데이터에 접근할 필요 없이도 효과적으로 작동합니다. 이 방법은 네 가지 분류 작업과 하나의 분할 작업에서 검증되었습니다. 연구는 스위스 국가 과학 재단과 토요타 유럽의 지원을 받았습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"CoTTA 논문 내용을 요약해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fec5cf6-4b02-4c97-aab5-f430c4dad8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tent 논문은 테스트 시점에서의 적응을 강조하며, 소스 데이터 없이 타겟 데이터만으로 모델의 일반화 오류를 줄이기 위한 엔트로피 최소화 방안을 제안합니다. 이 방법은 ImageNet-C 벤치마크에서 44.0%의 오류율을 기록하여 기존의 강력한 훈련 방법보다 우수한 성능을 보여줍니다. 또한, tent는 온라인 및 소스 없는 적응을 통해 다양한 아키텍처에서 일반화 가능성을 입증합니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tent 논문 내용을 요약해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564f37a-8a78-4ae2-9e23-4c75fca04c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3a62c-982f-4a7b-a32c-d20531620a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
